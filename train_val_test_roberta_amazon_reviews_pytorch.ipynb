{"cells":[{"cell_type":"markdown","metadata":{"id":"e98bePYoHrDa"},"source":["# Text Classification with RoBERTa using Pytorch.\n","\n","RoBERTa: A Robustly Optimized BERT Pretraining Approach is a recent [paper](https://arxiv.org/pdf/1907.11692.pdf) published by researchers at Facebook. \n","It modifies the key hyper-parameters in BERT model:\n","uses larger mini-batches, learning rates and step sizes for longer training\n","differences in masking procedure\n","\n","Roberta gets higher GLEU score as 88.5\n","\n","\n","In this notebook, I will be using RoBERTa with [Pytorch-Transformers](https://github.com/huggingface/pytorch-transformers) library. PyTorch-Transformers (formerly known as pytorch-pretrained-bert) is a library of state-of-the-art pre-trained models for Natural Language Processing (NLP).  \n","Most of the code in this notebook is from [run_glue.py](https://github.com/huggingface/pytorch-transformers/blob/master/examples/run_glue.py) file in the pytorch-transformers library. This entire notebook is developed using Google Colab."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34913,"status":"ok","timestamp":1607320054858,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"JXqBKc9XMFIE","outputId":"b55fb036-f234-442d-f886-6886e493b290"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34876,"status":"ok","timestamp":1607320054859,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"Kmw4ZGJPPUZC","outputId":"5af5e913-dd93-4f5d-f91c-9a47e8a753e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Dec  7 05:47:34 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44115,"status":"ok","timestamp":1607320064124,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"eZeNT0ogPxMq","outputId":"5aefdc30-091c-468f-bbd6-e7e51442eaab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting urllib3==1.25.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/7777358f672a14b7ae0dfcd29f949f409f913e0578190d6bfa68eb55864b/urllib3-1.25.4-py2.py3-none-any.whl (125kB)\n","\u001b[K     |████████████████████████████████| 133kB 8.7MB/s \n","\u001b[?25hCollecting awscli\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2f/db65135e5d82992ceb3294eae04bc6ceb7af25663a46f9c2f96c3bab6841/awscli-1.18.190-py2.py3-none-any.whl (3.4MB)\n","\u001b[K     |████████████████████████████████| 3.5MB 9.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML\u003c5.4,\u003e=3.10; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from awscli) (3.13)\n","Collecting botocore==1.19.30\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/a3/1ee497faf994d180df5d14d456eef1ef46ca1ffce617816faa4ff8164608/botocore-1.19.30-py2.py3-none-any.whl (7.0MB)\n","\u001b[K     |████████████████████████████████| 7.0MB 28.7MB/s \n","\u001b[?25hCollecting colorama\u003c0.4.4,\u003e=0.2.5; python_version != \"3.4\"\n","  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n","Collecting docutils\u003c0.16,\u003e=0.10\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n","\u001b[K     |████████████████████████████████| 552kB 43.7MB/s \n","\u001b[?25hCollecting s3transfer\u003c0.4.0,\u003e=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.3MB/s \n","\u001b[?25hCollecting rsa\u003c=4.5.0,\u003e=3.1.2; python_version != \"3.4\"\n","  Downloading https://files.pythonhosted.org/packages/26/f8/8127fdda0294f044121d20aac7785feb810e159098447967a6103dedfb96/rsa-4.5-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: python-dateutil\u003c3.0.0,\u003e=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore==1.19.30-\u003eawscli) (2.8.1)\n","Collecting jmespath\u003c1.0.0,\u003e=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: pyasn1\u003e=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa\u003c=4.5.0,\u003e=3.1.2; python_version != \"3.4\"-\u003eawscli) (0.4.8)\n","Requirement already satisfied, skipping upgrade: six\u003e=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil\u003c3.0.0,\u003e=2.1-\u003ebotocore==1.19.30-\u003eawscli) (1.15.0)\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","Installing collected packages: urllib3, jmespath, botocore, colorama, docutils, s3transfer, rsa, awscli\n","  Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Found existing installation: docutils 0.16\n","    Uninstalling docutils-0.16:\n","      Successfully uninstalled docutils-0.16\n","  Found existing installation: rsa 4.6\n","    Uninstalling rsa-4.6:\n","      Successfully uninstalled rsa-4.6\n","Successfully installed awscli-1.18.190 botocore-1.19.30 colorama-0.4.3 docutils-0.15.2 jmespath-0.10.0 rsa-4.5 s3transfer-0.3.3 urllib3-1.25.4\n"]}],"source":["!pip install --upgrade \"urllib3==1.25.4\" awscli"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49263,"status":"ok","timestamp":1607320069299,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"IWtCC3g1MZy0","outputId":"4c29b04f-04ea-499d-e8c4-8582ac382257"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pytorch-transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n","\r\u001b[K     |█▉                              | 10kB 18.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 15.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 12.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 7.8MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.18.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.23.0)\n","Requirement already satisfied: torch\u003e=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.7.0+cu101)\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/9c/544396572c05841b7a2482c88be5dd54dcd18ba97abeb1e8d34daf921a54/boto3-1.16.30-py2.py3-none-any.whl (129kB)\n","\u001b[K     |████████████████████████████████| 133kB 17.0MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 9.6MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 29.3MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-\u003epytorch-transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests-\u003epytorch-transformers) (1.25.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests-\u003epytorch-transformers) (2020.11.8)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-\u003epytorch-transformers) (2.10)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch\u003e=1.0.0-\u003epytorch-transformers) (0.16.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch\u003e=1.0.0-\u003epytorch-transformers) (0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch\u003e=1.0.0-\u003epytorch-transformers) (3.7.4.3)\n","Requirement already satisfied: jmespath\u003c1.0.0,\u003e=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3-\u003epytorch-transformers) (0.10.0)\n","Requirement already satisfied: botocore\u003c1.20.0,\u003e=1.19.30 in /usr/local/lib/python3.6/dist-packages (from boto3-\u003epytorch-transformers) (1.19.30)\n","Requirement already satisfied: s3transfer\u003c0.4.0,\u003e=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3-\u003epytorch-transformers) (0.3.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses-\u003epytorch-transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses-\u003epytorch-transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses-\u003epytorch-transformers) (0.17.0)\n","Requirement already satisfied: python-dateutil\u003c3.0.0,\u003e=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore\u003c1.20.0,\u003e=1.19.30-\u003eboto3-\u003epytorch-transformers) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=99397cf88150e32be6d39f9abbc11f8ae921d4f7bed97ec65bb6cb20a556be1c\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: boto3, sentencepiece, sacremoses, pytorch-transformers\n","Successfully installed boto3-1.16.30 pytorch-transformers-1.2.0 sacremoses-0.0.43 sentencepiece-0.1.94\n"]}],"source":["!pip install pytorch-transformers"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":53342,"status":"ok","timestamp":1607320073395,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"uSGTbxQiMnLs"},"outputs":[],"source":["import csv\n","import os\n","import random\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n","                              TensorDataset)\n","from torch.utils.data.distributed import DistributedSampler\n","from pytorch_transformers import RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer\n","from pytorch_transformers import AdamW, WarmupLinearSchedule\n","from tqdm import tqdm, trange, tqdm_notebook\n","from sklearn.metrics import matthews_corrcoef, f1_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n"]},{"cell_type":"markdown","metadata":{"id":"gH9PP7MBJtpn"},"source":["### Loading the Dataset.\n","I am using a small subset of Amazon Reviews Dataset containing only 10000 rows. You can use the whole dataset but it will take a much longer time to train."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":254},"executionInfo":{"elapsed":54594,"status":"ok","timestamp":1607320074695,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"QlpKgd1WM6xd","outputId":"d271350b-fa00-46b3-c760-c652ad6b9ba5"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eUnnamed: 0\u003c/th\u003e\n","      \u003cth\u003eClothing ID\u003c/th\u003e\n","      \u003cth\u003eAge\u003c/th\u003e\n","      \u003cth\u003eTitle\u003c/th\u003e\n","      \u003cth\u003eReview Text\u003c/th\u003e\n","      \u003cth\u003eRating\u003c/th\u003e\n","      \u003cth\u003eRecommended IND\u003c/th\u003e\n","      \u003cth\u003ePositive Feedback Count\u003c/th\u003e\n","      \u003cth\u003eDivision Name\u003c/th\u003e\n","      \u003cth\u003eDepartment Name\u003c/th\u003e\n","      \u003cth\u003eClass Name\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e767\u003c/td\u003e\n","      \u003ctd\u003e33\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003eAbsolutely wonderful - silky and sexy and comf...\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eInitmates\u003c/td\u003e\n","      \u003ctd\u003eIntimate\u003c/td\u003e\n","      \u003ctd\u003eIntimates\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e1080\u003c/td\u003e\n","      \u003ctd\u003e34\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003eLove this dress!  it's sooo pretty.  i happene...\u003c/td\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003eGeneral\u003c/td\u003e\n","      \u003ctd\u003eDresses\u003c/td\u003e\n","      \u003ctd\u003eDresses\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e1077\u003c/td\u003e\n","      \u003ctd\u003e60\u003c/td\u003e\n","      \u003ctd\u003eSome major design flaws\u003c/td\u003e\n","      \u003ctd\u003eI had such high hopes for this dress and reall...\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eGeneral\u003c/td\u003e\n","      \u003ctd\u003eDresses\u003c/td\u003e\n","      \u003ctd\u003eDresses\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1049\u003c/td\u003e\n","      \u003ctd\u003e50\u003c/td\u003e\n","      \u003ctd\u003eMy favorite buy!\u003c/td\u003e\n","      \u003ctd\u003eI love, love, love this jumpsuit. it's fun, fl...\u003c/td\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eGeneral Petite\u003c/td\u003e\n","      \u003ctd\u003eBottoms\u003c/td\u003e\n","      \u003ctd\u003ePants\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e847\u003c/td\u003e\n","      \u003ctd\u003e47\u003c/td\u003e\n","      \u003ctd\u003eFlattering shirt\u003c/td\u003e\n","      \u003ctd\u003eThis shirt is very flattering to all due to th...\u003c/td\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003eGeneral\u003c/td\u003e\n","      \u003ctd\u003eTops\u003c/td\u003e\n","      \u003ctd\u003eBlouses\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["   Unnamed: 0  Clothing ID  Age  ...   Division Name Department Name  Class Name\n","0           0          767   33  ...       Initmates        Intimate   Intimates\n","1           1         1080   34  ...         General         Dresses     Dresses\n","2           2         1077   60  ...         General         Dresses     Dresses\n","3           3         1049   50  ...  General Petite         Bottoms       Pants\n","4           4          847   47  ...         General            Tops     Blouses\n","\n","[5 rows x 11 columns]"]},"execution_count":6,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["dataset = pd.read_csv('/content/drive/My Drive/Colab Notebooks/women_clothes_review/Womens Clothing E-Commerce Reviews.csv')\n","dataset.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"elapsed":54517,"status":"ok","timestamp":1607320074696,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"FYdqYAmQQd0e","outputId":"c1aeb7c0-32dd-4334-ccec-72a0a2416783"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eReview Text\u003c/th\u003e\n","      \u003cth\u003eRating\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003eAbsolutely wonderful - silky and sexy and comf...\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003eLove this dress!  it's sooo pretty.  i happene...\u003c/td\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003eI had such high hopes for this dress and reall...\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003eI love, love, love this jumpsuit. it's fun, fl...\u003c/td\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003eThis shirt is very flattering to all due to th...\u003c/td\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["                                         Review Text  Rating\n","0  Absolutely wonderful - silky and sexy and comf...       4\n","1  Love this dress!  it's sooo pretty.  i happene...       5\n","2  I had such high hopes for this dress and reall...       3\n","3  I love, love, love this jumpsuit. it's fun, fl...       5\n","4  This shirt is very flattering to all due to th...       5"]},"execution_count":7,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["dataset = dataset.loc[:, ['Review Text', 'Rating']]\n","dataset.head()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54483,"status":"ok","timestamp":1607320074696,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"BDpDYA-VZC0S","outputId":"cd7e8281-0f0d-4edb-b5ca-74628a71dc62"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'pandas.core.frame.DataFrame'\u003e\n","RangeIndex: 23486 entries, 0 to 23485\n","Data columns (total 2 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   Review Text  22641 non-null  object\n"," 1   Rating       23486 non-null  int64 \n","dtypes: int64(1), object(1)\n","memory usage: 367.1+ KB\n"]}],"source":["dataset.info()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54459,"status":"ok","timestamp":1607320074697,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"uaVcAs2tZFzU","outputId":"0d95f96b-0060-4925-f9d3-7f75b7a75229"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'pandas.core.frame.DataFrame'\u003e\n","Int64Index: 22641 entries, 0 to 23485\n","Data columns (total 2 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   Review Text  22641 non-null  object\n"," 1   Rating       22641 non-null  int64 \n","dtypes: int64(1), object(1)\n","memory usage: 530.6+ KB\n"]}],"source":["dataset = dataset.dropna()\n","dataset.info()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":54444,"status":"ok","timestamp":1607320074698,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"pjJLul8IQwUk"},"outputs":[],"source":["def get_sentiment(value):\n","    if value \u003e 3:\n","        return 1\n","    else:\n","        return 0"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"elapsed":54410,"status":"ok","timestamp":1607320074699,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"vtfepK6MQ0_-","outputId":"4a53f03c-db9e-430a-f14f-433e3c01da1a"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eReview Text\u003c/th\u003e\n","      \u003cth\u003eRating\u003c/th\u003e\n","      \u003cth\u003eSentiment\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003eAbsolutely wonderful - silky and sexy and comf...\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003eLove this dress!  it's sooo pretty.  i happene...\u003c/td\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003eI had such high hopes for this dress and reall...\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003eI love, love, love this jumpsuit. it's fun, fl...\u003c/td\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003eThis shirt is very flattering to all due to th...\u003c/td\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["                                         Review Text  Rating  Sentiment\n","0  Absolutely wonderful - silky and sexy and comf...       4          1\n","1  Love this dress!  it's sooo pretty.  i happene...       5          1\n","2  I had such high hopes for this dress and reall...       3          0\n","3  I love, love, love this jumpsuit. it's fun, fl...       5          1\n","4  This shirt is very flattering to all due to th...       5          1"]},"execution_count":11,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["dataset['Sentiment'] = dataset['Rating'].apply(get_sentiment)\n","dataset.head()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"elapsed":54386,"status":"ok","timestamp":1607320074699,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"q10lxIB5RB2x","outputId":"d266de1b-7355-477b-c2b4-57a73c866a00"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eReview Text\u003c/th\u003e\n","      \u003cth\u003eSentiment\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003eAbsolutely wonderful - silky and sexy and comf...\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003eLove this dress!  it's sooo pretty.  i happene...\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003eI had such high hopes for this dress and reall...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003eI love, love, love this jumpsuit. it's fun, fl...\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003eThis shirt is very flattering to all due to th...\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["                                         Review Text  Sentiment\n","0  Absolutely wonderful - silky and sexy and comf...          1\n","1  Love this dress!  it's sooo pretty.  i happene...          1\n","2  I had such high hopes for this dress and reall...          0\n","3  I love, love, love this jumpsuit. it's fun, fl...          1\n","4  This shirt is very flattering to all due to th...          1"]},"execution_count":12,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["dataset.drop(['Rating'], axis=1, inplace=True)\n","dataset.head()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54371,"status":"ok","timestamp":1607320074700,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"o-qX5TwLP5Xp","outputId":"ebce9fcd-83ca-4802-899c-dddfc1885381"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                             Review Text  Sentiment\n","17229  The comfort of this fabric is terrific. the sw...          1\n","                                             Review Text  Sentiment\n","1893   Disappointment city with this one and i am so ...          0\n","15996  Loved these pants when i tried them on they lo...          0\n","(5661, 2)\n"]}],"source":["train_df, val_df = train_test_split(dataset, test_size=0.5, random_state=101)\n","val_df, test_df = train_test_split(val_df, test_size=0.5, random_state=101)\n","\n","dataset.shape,train_df.shape, val_df.shape, test_df.shape\n","print(test_df[:1])\n","print(test_df[-2:])\n","print(test_df.shape)"]},{"cell_type":"markdown","metadata":{"id":"wokvBC5TKJ3v"},"source":["Pytorch-Transformers library requires dataset to be divided in Train, Valid (read Dev) and Test set. In this case I will not be using a Test set. Also the library requires dataset to be in TSV format but since most of the times we get the data in CSV format, I have decided to use a CSV format."]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":54359,"status":"ok","timestamp":1607320074701,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"PNFzmbXbQFrU"},"outputs":[],"source":["save_dir = Path('/content/drive/My Drive/Colab Notebooks/Amazon Reviews')"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":55083,"status":"ok","timestamp":1607320075433,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"fpeAxTi5XN6t"},"outputs":[],"source":["if not os.path.exists(save_dir):\n","    os.mkdir(save_dir)\n","\n","fullname = os.path.join(save_dir, 'train.csv')    \n","train_df.to_csv(fullname)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":55049,"status":"ok","timestamp":1607320075438,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"95W56_FuXiml"},"outputs":[],"source":["# if not os.path.exists(save_dir):\n","#     os.mkdir(save_dir)\n","\n","# fullname = os.path.join(save_dir, 'dev.csv')    \n","# train_df.to_csv(fullname)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":55287,"status":"ok","timestamp":1607320075686,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"1vq4cDY2Szvs"},"outputs":[],"source":["if not os.path.exists(save_dir):\n","    os.mkdir(save_dir)\n","\n","fullname = os.path.join(save_dir, 'val.csv')    \n","val_df.to_csv(fullname)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":55968,"status":"ok","timestamp":1607320076396,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"_42V84YsS4Tt"},"outputs":[],"source":["if not os.path.exists(save_dir):\n","    os.mkdir(save_dir)\n","\n","fullname = os.path.join(save_dir, 'test.csv')    \n","test_df.to_csv(fullname)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":55951,"status":"ok","timestamp":1607320076397,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"Yb1A4FJ3UDqL"},"outputs":[],"source":["class InputExample(object):\n","    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n","\n","    def __init__(self, guid, text_a, text_b=None, label=None):\n","        \"\"\"Constructs a InputExample.\n","        Args:\n","            guid: Unique id for the example.\n","            text_a: string. The untokenized text of the first sequence. For single\n","            sequence tasks, only this sequence must be specified.\n","            text_b: (Optional) string. The untokenized text of the second sequence.\n","            Only must be specified for sequence pair tasks.\n","            label: (Optional) string. The label of the example. This should be\n","            specified for train and dev examples, but not for test examples.\n","        \"\"\"\n","        self.guid = guid\n","        self.text_a = text_a\n","        self.text_b = text_b\n","        self.label = label"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":55941,"status":"ok","timestamp":1607320076398,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"8zdf_yTwUPPo"},"outputs":[],"source":["class InputFeatures(object):\n","    \"\"\"A single set of features of data.\"\"\"\n","\n","    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.segment_ids = segment_ids\n","        self.label_id = label_id"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":55931,"status":"ok","timestamp":1607320076399,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"gnQUdWjFUSgN"},"outputs":[],"source":["class DataProcessor(object):\n","    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n","\n","    def get_train_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_dev_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_labels(self):\n","        \"\"\"Gets the list of labels for this data set.\"\"\"\n","        raise NotImplementedError()\n","\n","    @classmethod\n","    def _read_tsv(cls, input_file, quotechar=None):\n","        \"\"\"Reads a tab separated value file.\"\"\"\n","        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n","            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n","            lines = []\n","            for line in reader:\n","                if sys.version_info[0] == 2:\n","                    line = list(unicode(cell, 'utf-8') for cell in line)\n","                lines.append(line)\n","            return lines\n","          \n","class AmazonProcessor(DataProcessor):\n","    \"\"\"Processor for the Amazon Reviews data set.\"\"\"\n","\n","    def get_train_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        return self._create_examples(\n","            self._read_tsv(os.path.join(data_dir, \"train.csv\")), \"train\")\n","\n","    def get_dev_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        return self._create_examples(\n","            self._read_tsv(os.path.join(data_dir, \"dev.csv\")), \"dev\")\n","\n","    def get_test_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        df = pd.read_csv(os.path.join(data_dir,'test.csv'))\n","        print(df[:1])\n","        print(df[-2:])\n","\n","        return self._create_examples(\n","            self._read_tsv(os.path.join(data_dir, \"test.csv\")), \"test\")\n","        \n","\n","    def get_labels(self):\n","        \"\"\"See base class.\"\"\"\n","        return [0, 1]\n","\n","    #Hack to be compatible with the existing code in transformers library\n","    def _read_tsv(self, file_path):\n","        return pd.read_csv(file_path).values.tolist()\n","\n","    def _create_examples(self, lines, set_type):\n","        \"\"\"Creates examples for the training and dev sets.\"\"\"\n","        examples = []\n","        for (i, line) in enumerate(lines):\n","          # print(f'line: {line}')\n","          if i == 0:\n","              print(f'line0: {line[0]}')\n","              continue\n","          guid = \"%s-%s\" % (set_type, i)\n","          \n","          text_a = str(line[1])\n","           # text_b = None\n","          \n","          label = line[2]\n","          examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n","        return examples"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":55924,"status":"ok","timestamp":1607320076400,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"Ql8l2ChCmLjk"},"outputs":[],"source":["def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":55917,"status":"ok","timestamp":1607320076400,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"3WZhRbxumUB9"},"outputs":[],"source":["def simple_accuracy(preds, labels):\n","  return (preds == labels).mean()\n","  \n","def acc_and_f1(preds, labels):\n","  acc = simple_accuracy(preds, labels)\n","  f1 = f1_score(y_true=labels, y_pred=preds)\n","  return {\n","      \"acc\": acc,\n","      \"f1\": f1,\n","      \"acc_and_f1\": (acc + f1) / 2,\n","  }\n","\n","\n","def f1_macro(preds, labels):\n","  return f1_score(y_true=labels, y_pred=preds, average='macro')\n","  \n","def compute_metrics(task_name, preds, labels):\n","  assert len(preds) == len(labels)\n","  if task_name == \"amazon\":\n","    return {\"acc\": simple_accuracy(preds, labels)}\n","  else:\n","    raise KeyError(task_name)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":55887,"status":"ok","timestamp":1607320076401,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"Mz5S3bebWKmT"},"outputs":[],"source":["def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n","    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n","\n","    # This is a simple heuristic which will always truncate the longer sequence\n","    # one token at a time. This makes more sense than truncating an equal percent\n","    # of tokens from each, since if one sequence is very short then each token\n","    # that's truncated likely contains more information than a longer sequence.\n","    while True:\n","        total_length = len(tokens_a) + len(tokens_b)\n","        if total_length \u003c= max_length:\n","            break\n","        if len(tokens_a) \u003e len(tokens_b):\n","            tokens_a.pop()\n","        else:\n","            tokens_b.pop()\n"]},{"cell_type":"markdown","metadata":{"id":"4-EiBzz_KJoY"},"source":["### covert_examples_to_features"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":55877,"status":"ok","timestamp":1607320076402,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"95v1DULYWgR8"},"outputs":[],"source":["def convert_examples_to_features(examples, label_list, max_seq_length,\n","                                 tokenizer, output_mode,\n","                                 cls_token_at_end=False, pad_on_left=False,\n","                                 cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\n","                                 sequence_a_segment_id=0, sequence_b_segment_id=1,\n","                                 cls_token_segment_id=1, pad_token_segment_id=0,\n","                                 mask_padding_with_zero=True):\n","    \"\"\" Loads a data file into a list of `InputBatch`s\n","        `cls_token_at_end` define the location of the CLS token:\n","            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n","            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n","        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n","    \"\"\"\n","\n","    label_map = {label : i for i, label in enumerate(label_list)}\n","  \n","    features = []\n","    for (ex_index, example) in enumerate(examples):\n","        # print(f'ex_index:{ex_index}')\n","        # print(f'example:{example.guid}')\n","        # print(f'example:{example.text_a}')\n","        # print(f'example:{example.text_b}')\n","        # print(f'example.label:{example.label}')\n","\n","\n","        tokens_a = tokenizer.tokenize(example.text_a)\n","        # print(f'tokens_a:{tokens_a}')\n","\n","        tokens_b = None\n","        if example.text_b:\n","            tokens_b = tokenizer.tokenize(example.text_b)\n","            # Modifies `tokens_a` and `tokens_b` in place so that the total\n","            # length is less than the specified length.\n","            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n","            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n","        else:\n","            # Account for [CLS] and [SEP] with \"- 2\"\n","            if len(tokens_a) \u003e max_seq_length - 2:\n","                tokens_a = tokens_a[:(max_seq_length - 2)]\n","\n","        # The convention in BERT is:\n","        # (a) For sequence pairs:\n","        #  tokens:   [CLS] is this jack son ville ? [SEP] no it is not . [SEP]\n","        #  type_ids:   0   0   0    0    0   0    0   0   1  1  1  1   1   1\n","        # (b) For single sequences:\n","        #  tokens:   [CLS] the dog is hairy . [SEP]\n","        #  type_ids:   0   0   0   0  0     0   0\n","        #\n","        # Where \"type_ids\" are used to indicate whether this is the first\n","        # sequence or the second sequence. The embedding vectors for `type=0` and\n","        # `type=1` were learned during pre-training and are added to the wordpiece\n","        # embedding vector (and position vector). This is not *strictly* necessary\n","        # since the [SEP] token unambiguously separates the sequences, but it makes\n","        # it easier for the model to learn the concept of sequences.\n","        #\n","        # For classification tasks, the first vector (corresponding to [CLS]) is\n","        # used as as the \"sentence vector\". Note that this only makes sense because\n","        # the entire model is fine-tuned.\n","        tokens = tokens_a + [sep_token]\n","        segment_ids = [sequence_a_segment_id] * len(tokens)\n","\n","        if tokens_b:\n","            tokens += tokens_b + [sep_token]\n","            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n","\n","        if cls_token_at_end:\n","            tokens = tokens + [cls_token]\n","            segment_ids = segment_ids + [cls_token_segment_id]\n","        else:\n","            tokens = [cls_token] + tokens\n","            segment_ids = [cls_token_segment_id] + segment_ids\n","\n","        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","        # print(f'tokens:{tokens}')\n","\n","        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n","        # tokens are attended to.\n","        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n","\n","        # Zero-pad up to the sequence length.\n","        padding_length = max_seq_length - len(input_ids)\n","        if pad_on_left:\n","            input_ids = ([pad_token] * padding_length) + input_ids\n","            input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n","            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n","        else:\n","            input_ids = input_ids + ([pad_token] * padding_length)\n","            input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n","            segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n","\n","        assert len(input_ids) == max_seq_length\n","        assert len(input_mask) == max_seq_length\n","        assert len(segment_ids) == max_seq_length\n","\n","        if output_mode == \"classification\":\n","          # print(f'label_map:{label_map}')\n","          # print(f'example.label:{example.label}')\n","          label_id = label_map[example.label]\n","          # print(f'lable_id:{label_id}')\n","        elif output_mode == \"regression\":\n","          label_id = float(example.label)\n","        else:\n","          raise KeyError(output_mode)\n","\n","        # print(f'input_ids:{input_ids}')\n","        # print(f'input_mask:{input_mask}')\n","        # print(f'segment_ids:{segment_ids}')\n","        # print(f'label_id:{label_id}')\n","\n","        features.append(\n","                InputFeatures(input_ids=input_ids,\n","                              input_mask=input_mask,\n","                              segment_ids=segment_ids,\n","                              label_id=label_id))\n","        \n","\n","\n","    return features"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55854,"status":"ok","timestamp":1607320076402,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"ja5cs8FCW8MH","outputId":"e87c9286-bb33-40e8-dcfe-c60bead01e79"},"outputs":[{"name":"stdout","output_type":"stream","text":["2\n"]}],"source":["processor = AmazonProcessor()\n","label_list = processor.get_labels()\n","num_labels = len(label_list)\n","print(num_labels)"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":55826,"status":"ok","timestamp":1607320076403,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"hQyQmYxzXXL3"},"outputs":[],"source":["# config = BertConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","# model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79031,"status":"ok","timestamp":1607320099614,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"Rl6qH0cvI8-T","outputId":"3d5626d1-ce5c-4941-f99a-473b2f795b1c"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 481/481 [00:00\u003c00:00, 349949.74B/s]\n","100%|██████████| 898823/898823 [00:00\u003c00:00, 2270873.96B/s]\n","100%|██████████| 456318/456318 [00:00\u003c00:00, 1399349.44B/s]\n","100%|██████████| 501200538/501200538 [00:13\u003c00:00, 36382271.19B/s]\n"]}],"source":["config = RobertaConfig.from_pretrained('roberta-base', num_labels=num_labels)\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","model = RobertaForSequenceClassification.from_pretrained('roberta-base', config=config)"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":79028,"status":"ok","timestamp":1607320099617,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"8-kjgtmBZEd8"},"outputs":[],"source":["def load_and_cache_examples(tokenizer, dataset='train'):  \n","  if dataset == \"train\":\n","      examples = processor.get_train_examples(data_dir)\n","  elif dataset == \"dev\":\n","      examples = processor.get_dev_examples(data_dir)\n","  else:\n","      examples = processor.get_test_examples(data_dir)\n","  \n","  features = convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, output_mode,\n","            cls_token_at_end=False,            # xlnet has a cls token at the end\n","            cls_token=tokenizer.cls_token,\n","            sep_token=tokenizer.sep_token,\n","            cls_token_segment_id=0,\n","            pad_on_left=False,                 # pad on the left for xlnet\n","            pad_token_segment_id=0)\n","  # Convert to Tensors and build dataset\n","  all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n","  all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n","  all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n","  if output_mode == \"classification\":\n","      all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n","      print(len(all_label_ids))\n","  elif output_mode == \"regression\":\n","      all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n","\n","  dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n","  return dataset\n","  "]},{"cell_type":"markdown","metadata":{"id":"SXOM4sldLaNO"},"source":["Hyperparameters are from the library. I have not fine tuned it."]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79024,"status":"ok","timestamp":1607320099619,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"WS3i_TnRaoTZ","outputId":"efa772d9-d84c-4693-a0ea-5143794c0bc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["output_mode = 'classification'\n","max_seq_length = 128\n","batch_size = 8\n","max_grad_norm = 1.0\n","gradient_accumulation_steps=2\n","num_train_epochs=3\n","weight_decay=0.0\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":79010,"status":"ok","timestamp":1607320099620,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"v8SNl4G1nQzL"},"outputs":[],"source":["learning_rate = 2e-5\n","adam_epsilon = 1e-8\n","warmup_steps = 0"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":79001,"status":"ok","timestamp":1607320099621,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"4-gCnXsga5Ca"},"outputs":[],"source":["def train(train_dataset, model, tokenizer):\n","  \"\"\" Train the model \"\"\"\n","  train_sampler = RandomSampler(train_dataset)\n","  train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n","  t_total = len(train_dataloader) // gradient_accumulation_steps * num_train_epochs\n","  # Prepare optimizer and schedule (linear warmup and decay)\n","  no_decay = ['bias', 'LayerNorm.weight']\n","  optimizer_grouped_parameters = [\n","      {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n","      {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","      ]\n","  optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\n","  scheduler = WarmupLinearSchedule(optimizer, warmup_steps=warmup_steps, t_total=t_total)\n","  \n","  global_step = 0\n","  tr_loss, logging_loss = 0.0, 0.0\n","  model.zero_grad()\n","\n","  train_iterator = tqdm_notebook(range(int(num_train_epochs)), desc=\"Epoch\")\n","  set_seed(42)\n","  for _ in train_iterator:\n","    preds = None\n","    epoch_iterator = tqdm_notebook(train_dataloader, desc=\"Iteration\")\n","    for step, batch in enumerate(epoch_iterator):\n","      model.train()\n","      batch = tuple(t.to(device) for t in batch)\n","      inputs = {'input_ids':      batch[0],\n","                'attention_mask': batch[1],\n","                'token_type_ids': None,       # XLM and RoBERTa don't use segment_ids\n","                'labels':         batch[3]}\n","      outputs = model(**inputs)\n","   # add code to calculate the acc\n","      tmp_eval_loss, logits = outputs[:2]\n","      if preds is None:\n","        preds = logits.detach().cpu().numpy()\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\n","      else:\n","        preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","\n","      loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n","      if gradient_accumulation_steps \u003e 1:\n","        loss = loss / gradient_accumulation_steps\n","      loss.backward()\n","      torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","      tr_loss += loss.item()\n","      if (step + 1) % gradient_accumulation_steps == 0:\n","          scheduler.step()  # Update learning rate schedule\n","          optimizer.step()\n","          model.zero_grad()\n","          global_step += 1\n","    if output_mode == \"classification\":\n","      preds = np.argmax(preds, axis=1)\n","    elif output_mode == \"regression\":\n","      preds = np.squeeze(preds)\n","    result = compute_metrics(\"amazon\", preds, out_label_ids)\n","    print(results)\n","  return global_step, tr_loss / global_step, result"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":78995,"status":"ok","timestamp":1607320099622,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"2dSp0egsPYRw"},"outputs":[],"source":["def train_validation(train_dataset, validation_dataset, model, tokenizer):\n","  \"\"\" Train the model \"\"\"\n","  train_sampler = RandomSampler(train_dataset)\n","  train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n","  t_total = len(train_dataloader) // gradient_accumulation_steps * num_train_epochs\n","  # Prepare optimizer and schedule (linear warmup and decay)\n","  no_decay = ['bias', 'LayerNorm.weight']\n","  optimizer_grouped_parameters = [\n","      {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n","      {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","      ]\n","  optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\n","  scheduler = WarmupLinearSchedule(optimizer, warmup_steps=warmup_steps, t_total=t_total)\n","  \n","  global_step = 0\n","  tr_loss, logging_loss = 0.0, 0.0\n","  model.zero_grad()\n","\n","  train_iterator = tqdm_notebook(range(int(num_train_epochs)), desc=\"Epoch\")\n","  set_seed(42)\n","\n","  best_accuracy = 0\n","\n","  for _ in train_iterator:\n","    preds = None\n","    epoch_iterator = tqdm_notebook(train_dataloader, desc=\"Iteration\")\n","    for step, batch in enumerate(epoch_iterator):\n","      model.train()\n","      batch = tuple(t.to(device) for t in batch)\n","      inputs = {'input_ids':      batch[0],\n","                'attention_mask': batch[1],\n","                'token_type_ids': None,       # XLM and RoBERTa don't use segment_ids\n","                'labels':         batch[3]}\n","      outputs = model(**inputs)\n","    # add code to calculate the acc\n","      tmp_eval_loss, logits = outputs[:2]\n","      if preds is None:\n","        preds = logits.detach().cpu().numpy()\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\n","      else:\n","        preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","\n","      loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n","      if gradient_accumulation_steps \u003e 1:\n","        loss = loss / gradient_accumulation_steps\n","      loss.backward()\n","      torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","      tr_loss += loss.item()\n","      if (step + 1) % gradient_accumulation_steps == 0:\n","          scheduler.step()  # Update learning rate schedule\n","          optimizer.step()\n","          model.zero_grad()\n","          global_step += 1\n","    if output_mode == \"classification\":\n","      preds = np.argmax(preds, axis=1)\n","    elif output_mode == \"regression\":\n","      preds = np.squeeze(preds)\n","    result = compute_metrics(\"amazon\", preds, out_label_ids)\n","    train_acc = result['acc']\n","\n","\n","    print(f'the train accuracy is {train_acc}')\n","    val_result, preds, out_label_ids, preds_p = evaluate_updated(validation_dataset, model, tokenizer, prefix=global_step)\n","    val_acc = val_result['acc']\n","    print(f'the validation accuracy is {val_acc}')\n","\n","    if  val_acc \u003e best_accuracy:\n","      best_accuracy = val_acc\n","      torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/Amazon Reviews/models/best_model.pt') \n","    \n","\n","  return global_step, tr_loss / global_step, result, preds_p"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":78990,"status":"ok","timestamp":1607320099623,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"RTmq55jBgdEB"},"outputs":[],"source":["def sigmoid(x):\n","  z = 1/(1 + np.exp(-x))\n","  return z"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78984,"status":"ok","timestamp":1607320099624,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"OTh7lIcqjW5y","outputId":"a50805b8-7020-4a44-f9a7-dd0cc2ce5cb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.91053019 0.10613508]\n"," [0.85395734 0.14981748]\n"," [0.03050083 0.9555538 ]]\n"]}],"source":["p = np.array([[ 2.3201258, -2.130842 ],\n"," [ 1.7659825, -1.7360333],\n"," [-3.4590256,  3.0680115]])\n","p1 = sigmoid(p)\n","print(p1)"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":78972,"status":"ok","timestamp":1607320099624,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"LVT16BvoPlp1"},"outputs":[],"source":["def evaluate_updated(dataset, model, tokenizer, prefix=\"\"):\n","  results = {}\n","  # eval_dataset = load_and_cache_examples(tokenizer, dataset='dev')\n","  eval_dataset = dataset\n","  eval_batch_size = 8\n","  eval_sampler = SequentialSampler(eval_dataset)\n","  eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size)\n","  eval_loss = 0.0\n","  nb_eval_steps = 0\n","  preds = None\n","  preds_p = None\n","  out_label_ids = None\n","  for batch in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n","    model.eval()\n","    batch = tuple(t.to(device) for t in batch)\n","    with torch.no_grad():\n","      inputs = {'input_ids':      batch[0],\n","                'attention_mask': batch[1],\n","                'token_type_ids': None,             # XLM and RoBERTa don't use segment_ids\n","                'labels':         batch[3]}\n","      outputs = model(**inputs)\n","      tmp_eval_loss, logits = outputs[:2]\n","      eval_loss += tmp_eval_loss.mean().item()\n","    \n","    nb_eval_steps += 1\n","    if preds is None:\n","        preds = logits.detach().cpu().numpy()\n","        print(preds)\n","        print(np.argmax(preds,axis=1))\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\n","        print(f'out_label_ids is: {out_label_ids}')\n","        preds_p = sigmoid(preds)\n","        print(f'pred probability is {preds_p}')\n","    else:\n","        preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","        temp = logits.detach().cpu().numpy()\n","        preds_p = np.append(preds_p,sigmoid(temp),axis = 0)\n","  eval_loss = eval_loss / nb_eval_steps\n","  if output_mode == \"classification\":\n","      preds = np.argmax(preds, axis=1)\n","  elif output_mode == \"regression\":\n","      preds = np.squeeze(preds)\n","  result = compute_metrics(\"amazon\", preds, out_label_ids)\n","  return result, preds, out_label_ids,preds_p"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":78967,"status":"ok","timestamp":1607320099625,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"D1UJhmRdfJM0"},"outputs":[],"source":["def evaluate(model, tokenizer, prefix=\"\"):\n","  results = {}\n","  eval_dataset = load_and_cache_examples(tokenizer, dataset='dev')\n","  eval_batch_size = 8\n","  eval_sampler = SequentialSampler(eval_dataset)\n","  eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size)\n","  eval_loss = 0.0\n","  nb_eval_steps = 0\n","  preds = None\n","  out_label_ids = None\n","  for batch in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n","    model.eval()\n","    batch = tuple(t.to(device) for t in batch)\n","    with torch.no_grad():\n","      inputs = {'input_ids':      batch[0],\n","                'attention_mask': batch[1],\n","                'token_type_ids': None,             # XLM and RoBERTa don't use segment_ids\n","                'labels':         batch[3]}\n","      outputs = model(**inputs)\n","      tmp_eval_loss, logits = outputs[:2]\n","      eval_loss += tmp_eval_loss.mean().item()\n","    \n","    nb_eval_steps += 1\n","    if preds is None:\n","        preds = logits.detach().cpu().numpy()\n","        print(preds)\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\n","        \n","    else:\n","        preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","  eval_loss = eval_loss / nb_eval_steps\n","  if output_mode == \"classification\":\n","      preds = np.argmax(preds, axis=1)\n","  elif output_mode == \"regression\":\n","      preds = np.squeeze(preds)\n","  result = compute_metrics(\"amazon\", preds, out_label_ids)\n","  return result, preds, out_label_ids"]},{"cell_type":"markdown","metadata":{"id":"-_hyll0JLsFV"},"source":["### Train the Model"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89401,"status":"ok","timestamp":1607320110070,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"cyijMZfuiVFb","outputId":"0124916a-b8ba-4a0c-810c-754c406b7b8e"},"outputs":[{"data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n","      (position_embeddings): Embedding(514, 768)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"execution_count":38,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["data_dir= '/content/drive/My Drive/Colab Notebooks/Amazon Reviews'\n","model.to(device)"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":89392,"status":"ok","timestamp":1607320110071,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"51BlhviejxV7"},"outputs":[],"source":["# train_dataset = load_and_cache_examples(tokenizer, dataset=\"train\")\n","# # global_step, tr_loss, result = train(train_dataset, model, tokenizer)\n","\n","# validation_dataset = load_and_cache_examples(tokenizer, dataset=\"val\")\n","# global_step, tr_loss, result,preds_p = train_validation(train_dataset, validation_dataset, model, tokenizer)\n","# print(result)"]},{"cell_type":"markdown","metadata":{"id":"A0K1Fq8fQyQz"},"source":["### Evaluate the Model"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2635,"status":"ok","timestamp":1607320118651,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"zVTChDY8i_aq"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Unnamed: 0                                        Review Text  Sentiment\n","0       17229  The comfort of this fabric is terrific. the sw...          1\n","      Unnamed: 0                                        Review Text  Sentiment\n","5659        1893  Disappointment city with this one and i am so ...          0\n","5660       15996  Loved these pants when i tried them on they lo...          0\n","line0: 17229\n","5660\n"]},{"data":{"text/plain":["\u003cAll keys matched successfully\u003e"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluation\n","test_dataset = load_and_cache_examples(tokenizer, dataset=\"test\")\n","model.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/Amazon Reviews/models/best_model.pt') )"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1607320118652,"user":{"displayName":"Ally Qin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifowWU9o7AxileU8mJT4KneVd1zFKDJ-LYBvDtUQ=s64","userId":"10818386492934589810"},"user_tz":480},"id":"pHmNmkhcBdRT"},"outputs":[{"data":{"text/plain":["(tensor([[    0,    38,  2740,  ...,     0,     0,     0],\n","         [    0,    38,    33,  ...,     0,     0,     0],\n","         [    0,    85,    18,  ...,     0,     0,     0],\n","         ...,\n","         [    0, 31407,  1827,  ...,     0,     0,     0],\n","         [    0, 39133, 36113,  ...,     0,     0,     0],\n","         [    0,   226, 12677,  ...,     0,     0,     0]]),\n"," tensor([[1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         ...,\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0]]),\n"," tensor([[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]]),\n"," tensor([0, 0, 1,  ..., 0, 0, 0]))"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["test_dataset.tensors"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UjFGRHwjA30L","outputId":"28e45926-0c4e-47cf-fe3a-5c0cbd77063c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  del sys.path[0]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"731ef967d0fa40fea71f39bb4c4b7024","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=708.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[[ 3.4504106 -3.1221192]\n"," [ 3.335963  -3.0291033]\n"," [-4.1574306  4.0520906]\n"," [ 3.4588935 -3.1290665]\n"," [-4.1802464  4.0835824]\n"," [-4.127984   4.0149918]\n"," [-4.1551948  4.048172 ]\n"," [ 2.5322585 -2.3692017]]\n","[0 0 1 0 1 1 1 0]\n","out_label_ids is: [0 0 1 0 1 1 1 0]\n","pred probability is [[0.9692434  0.04220403]\n"," [0.96564215 0.04612827]\n"," [0.01540663 0.98291117]\n"," [0.96949524 0.04192409]\n"," [0.01506433 0.9834321 ]\n"," [0.01585975 0.9822766 ]\n"," [0.01544059 0.9828452 ]\n"," [0.9263725  0.08555157]]\n"]}],"source":["   \n","result, y_pred, labels,preds_p = evaluate_updated(test_dataset, model, tokenizer, prefix=\"\")\n","y_true = pd.Dataframe(labels)\n","y_true.to_csv( '/content/drive/My\\ Drive/probability_csv_folder')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tGLqXaG0MEb8"},"outputs":[],"source":["%cd /content/drive/My\\ Drive/probability_csv_folder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sXXDMJIoMIbc"},"outputs":[],"source":["file_list = os.listdir('.')\n","df_name_list =[]\n","for file in file_list:\n","  df_name_list.append(file.split('.')[0])\n","df_name_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2THG8Oh6MRbX"},"outputs":[],"source":["for i,file in enumerate(file_list):\n","  df = pd.read_csv(file)\n","  if (i == 2):\n","    df_name_list[i] = df[1:]\n","  else:\n","    df_name_list[i] = df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sFsLJrZiMYUh"},"outputs":[],"source":["r = len(df_name_list[0])\n","r2= len(df_name_list[2])\n","print(r2)\n","p = np.zeros((r,2))\n","\n","for i,df in enumerate(df_name_list):\n","  p_temp = df.to_numpy()\n","  p = np.add(p, p_temp[:,1:])\n","pred_ensemble = np.argmax(p,axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jjV-3nf-Xl2W"},"outputs":[],"source":["def most_frequent(List): \n","    dict = {} \n","    count, itm = 0, '' \n","    for item in reversed(List): \n","        dict[item] = dict.get(item, 0) + 1\n","        if dict[item] \u003e= count : \n","            count, itm = dict[item], item \n","    return(itm) \n","  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NX1g9YLdRj3T"},"outputs":[],"source":["p = np.zeros((r,2))\n","pred_list=[]\n","for i,df in enumerate(df_name_list):\n","  p_temp = df.to_numpy()\n","  pred = np.argmax(p_temp[:,1:],axis=1)\n","  # pred = pred.reshape(-1,r)\n","  pred_list.append(pred)\n","pred_list = np.array(pred_list)\n","pred_list.shape\n","pred_vote =[]\n","for i in range(r):\n","  temp = pred_list[:,i]\n","  pred_vote.append(most_frequent(temp))\n","  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NxPU87LhNhN7"},"outputs":[],"source":["def acc(pred_ensemble,labels):\n","  cnt = 0\n","  for pred,label in zip(pred_ensemble,labels):\n","    if(pred == label):\n","      cnt +=1\n","  acc_ensemble = cnt/len(labels)\n","  return(acc_ensemble)\n","print(acc_ensemble)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ThC_gAv-YakW"},"outputs":[],"source":["acc_vote = acc(pred_vote,labels)\n","print(acc_vote)\n","\n","cnf_mat = confusion_matrix(labels, pred_vote)\n","\n","abbreviations=['negative','positive']\n","fig, ax = plt.subplots(1)\n","ax = sns.heatmap(cnf_mat, ax=ax, cmap=plt.cm.Blues, annot=True, fmt='g')\n","ax.set_xticklabels(abbreviations)\n","ax.set_yticklabels(abbreviations)\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Class')\n","plt.ylabel('True Class')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m4NPkk1AMm6p"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","cnf_mat = confusion_matrix(labels, pred_ensemble)\n","\n","abbreviations=['negative','positive']\n","fig, ax = plt.subplots(1)\n","ax = sns.heatmap(cnf_mat, ax=ax, cmap=plt.cm.Blues, annot=True, fmt='g')\n","ax.set_xticklabels(abbreviations)\n","ax.set_yticklabels(abbreviations)\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Class')\n","plt.ylabel('True Class')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FLB3xuD5kuRL"},"outputs":[],"source":["# result, y_pred, labels = evaluate(model, tokenizer, prefix=global_step)\n","print(result)\n","print(len(preds_p)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfyqrGRkuSQc"},"outputs":[],"source":["row_index = [i for i in range(len(preds_p))]\n","df = pd.DataFrame(data=preds_p, index=row_index, columns=[\"pred_0\", \"pred_1\"])\n","df.to_csv('/content/drive/My Drive/Colab Notebooks/women_clothes_review/preds_prob.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-syqgax_bRVu"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","cnf_mat = confusion_matrix(labels, y_pred)\n","\n","abbreviations=['negative','positive']\n","fig, ax = plt.subplots(1)\n","ax = sns.heatmap(cnf_mat, ax=ax, cmap=plt.cm.Blues, annot=True, fmt='g')\n","ax.set_xticklabels(abbreviations)\n","ax.set_yticklabels(abbreviations)\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Class')\n","plt.ylabel('True Class')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O8N3ZrSbdF7w"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"train_val_test_roberta_amazon_reviews_pytorch.ipynb","provenance":[{"file_id":"19QLWzpeQlwKpULQr83DwYKhz0xkp05Fy","timestamp":1606177622563},{"file_id":"1FvzruK1gZn2fJlGzji17jwEqFWQxb1U2","timestamp":1605983761748},{"file_id":"1GogRyM-LjZ81jibPUa0z5vUdSLxCWkYE","timestamp":1605764864359}],"toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"731ef967d0fa40fea71f39bb4c4b7024":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78b9c54f44074a71993a2877eb0e3857","IPY_MODEL_daa72ea1a1b74ae2a7ba18577abc779f"],"layout":"IPY_MODEL_82730e782461491d8b2dfc0d5ea9b50d"}},"78b9c54f44074a71993a2877eb0e3857":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Evaluating:   1%","description_tooltip":null,"layout":"IPY_MODEL_c78ac926d17e46faa17aa635d9b0bf15","max":708,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61843ea6cc494c17bad4634c0b545ce7","value":7}},"82730e782461491d8b2dfc0d5ea9b50d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"daa72ea1a1b74ae2a7ba18577abc779f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a83144ce6b842429627a9b8a716b797","placeholder":"​","style":"IPY_MODEL_55e10e2487014755b8d85ba3c344e9cf","value":" 7/708 [00:00\u0026lt;01:18,  8.88it/s]"}}}}},"nbformat":4,"nbformat_minor":0}